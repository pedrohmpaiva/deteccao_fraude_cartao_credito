{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sC2BFMOKN1M7"
   },
   "source": [
    "<img alt=\"Colaboratory logo\" width=\"15%\" src=\"https://github.com/pedrohmpaiva/portfolio/blob/main/banner.png?raw=true\">\n",
    "\n",
    "*por: [Pedro Henrique M. Paiva](https://www.linkedin.com/in/pedro-henrique-paiva/)*  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IR56trFcPcC1"
   },
   "source": [
    "# Detecção de Fraude em Cartões de Crédito\n",
    "\n",
    "Neste projeto,suregido pelo curso [DSNP - Sigmoidal](https://sigmoidal.ai/), iremos abordar o problema das fraudes em cartões de crédito, uma das principais preocupações das instituições financeiras como bancos e *fintechs*. Segundo [esta matéria](https://valorinveste.globo.com/produtos/servicos-financeiros/noticia/2020/02/12/brasil-e-2o-pais-da-america-latina-com-mais-fraudes-no-cartao-em-compras-online.ghtml), em 2020 o Brasil foi o 2º país da américa latina com mais fraudes em compras online e no primeiro semestre de 2021 [teve alta de quase 33% nas tentativas de fraude com cartão de crédito](https://www.infomoney.com.br/minhas-financas/brasil-teve-alta-de-quase-33-nas-tentativas-de-fraude-com-cartao-de-credito-no-1-semestre-mostra-estudo/).\n",
    "\n",
    "<p align=center>\n",
    "<img src=\"https://img.freepik.com/fotos-gratis/homem-hacker-no-laptop_144627-25527.jpg?w=1380&t=st=1650512651~exp=1650513251~hmac=71e86ae27a9ebabffa336182bf8bce35a568a1f0261b81339b5bc789ed16efce\" width=\"90%\"></p>\n",
    "\n",
    "Dentre essas fraudes, aquelas envolvendo cartões de crédito são de grande relevância uma vez que a sua não-detecção acaretará em prejuízos consideráveis, tanto para o consumidor quanto para a instituição financeira.\n",
    "\n",
    "Por todos esses motivos, o investimento na área de detecção de fraudes por meio de Inteligência Artificial vem crescendo a cada ano, representando uma grande oportunidade em *Data Science*. \n",
    "\n",
    "Dispondo de grandes volumes de dados como base histórica, um algoritmo de machine learning apenas um pouco melhor que os anteriores já representa uma economia de milhões de Reais. E esse é o desafio, aprimorar cada vez mais o uso de algoritmos visando inibir ou evitar transações fraudulentas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HVmpIxQWT4Y"
   },
   "source": [
    "## Importando os Dados\n",
    "\n",
    "Os dados que usaremos neste projeto foram disponibilizados por algumas empresas européias de cartão de crédito. O *dataset* representa as operações financeiras que aconteceram no período de dois dias, onde foram classificadas 492 fraudes em meio a quase 290 mil transações.\n",
    "<p align=center>\n",
    "    <img src=\"https://img.freepik.com/fotos-gratis/cartao-de-plastico-do-banco-pendurado-no-gancho-de-pesca-closeup-conceito-de-fraude-na-internet_151013-35671.jpg?w=1800\" width=\"50%\" align = right></p>\n",
    "\n",
    "\n",
    "Como você pode notar, este é um conjunto de dados extremamente desbalanceado, onde as fraudes representam apenas 0,17% do total.\n",
    "\n",
    "Outro detalhe é que as *features* são todas numéricas, e foram descaracterizadas (por preservação da privacidade e da segurança). Assim, os nomes das colunas são representados por $[V1, V2, V3 \\dots, V28]$ \n",
    "\n",
    "\n",
    "\n",
    "[Na página original dos dados](https://www.kaggle.com/mlg-ulb/creditcardfraud), também é informado que as variáveis passaram por uma transformação conhecida como Análise de Componentes Principais (*Principal Component Analysis* - PCA).\n",
    "\n",
    "A PCA permite a redução da dimensionalidade enquanto mantém o maior número possível de informações. Para conseguir isso, o algoritmo encontra um conjunto novo de recursos - os chamados **componentes**.\n",
    "\n",
    "Esses componentes são em número menor or igual às variáveis originais. No caso deste projeto, os componentes achados pela transformação da PCA são as próprias colunas $[V1, V2, V3 \\dots, V28]$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "id": "oQ4bNy7udtEE"
   },
   "outputs": [],
   "source": [
    "# importando os pacotes necessários\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.metrics         import accuracy_score\n",
    "from sklearn.metrics         import classification_report\n",
    "from sklearn.metrics         import r2_score\n",
    "from sklearn.metrics         import confusion_matrix\n",
    "from sklearn.metrics         import mean_squared_error\n",
    "from sklearn.tree            import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NxUOfDOj2j8"
   },
   "outputs": [],
   "source": [
    "# importando os dados para um DataFrame\n",
    "\n",
    "file_path = \"https://www.dropbox.com/s/b44o3t3ehmnx2b7/creditcard.csv?dl=1\"\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nF_Dhd81Cvq"
   },
   "source": [
    "---\n",
    "Com os dados importados para dentro de uma estrutura *Dataframe* - e não havendo a necessidade de mais nenhum ajuste ou configuração nesta etapa, pode-se iniciar uma análise exploratória dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UtXyZ6stlSM"
   },
   "source": [
    "# Análise Exploratória\n",
    "\n",
    "O objetivo desta etapa é ver o que inicialmente os dados tem a nos oferecer em insights, verificar a distribuição das classes, verificar se há valores ausentes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando as 5 primeiras entradas e a dimensão do dataset\n",
    "\n",
    "print('*** Dimensionalidade do dataset {} ***'.format(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando algumas informações sobre o dataset e suas features\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando se há valores ausentes\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resumo estatístico do dataset\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando a distribuição de classes\n",
    "\n",
    "semFraude = df['Class'].value_counts()[0]\n",
    "fraude = df['Class'].value_counts()[1]\n",
    "print('Transações normais: {}'.format(semFraude))\n",
    "print('Transações fraudulentas: {}'.format(fraude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cores\n",
    "\n",
    "preto_titulo = '#363434'\n",
    "preto_elementos = '#5c5757'\n",
    "azul = '#1f4287' # original da paleta: '#62929a' alternativa: #4b89ac\n",
    "cinza = '#efecec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotando um grafico da distribuição das classes\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.countplot(df['Class'], color= azul)\n",
    "\n",
    "ax.set_title('Gráfico de distribuição das classes', \n",
    "             fontsize = 20, \n",
    "             color = preto_titulo, \n",
    "             loc = 'left', \n",
    "             pad= 60, \n",
    "             fontweight= 'bold')\n",
    "\n",
    "ax.text(-0.5,320000, \n",
    "        'Ocorrências de transações fraudulentas\\ne não-fraudulentas', \n",
    "        fontsize = 13, color = preto_elementos)\n",
    "\n",
    "ax.set_xticklabels(labels=['Normal', 'Fraude'])\n",
    "ax.set_xlabel('Transações',  fontsize = 12, color= preto_elementos)\n",
    "ax.set_ylabel('Ocorrências', fontsize = 12, color= preto_elementos)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "ax.annotate(semFraude, \n",
    "            xy=(-0.11, 290000), \n",
    "            color = preto_elementos, \n",
    "            fontsize= 20,\n",
    "            fontweight='light')\n",
    "ax.annotate(fraude, \n",
    "            xy=(0.93, 9000), \n",
    "            color = preto_elementos, \n",
    "            fontsize= 20,\n",
    "            fontweight='light')\n",
    "\n",
    "ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotando os histogramas da variável \"Time\" (Fraude e não-fraude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável \"Time\" representa o tempo (em segundos) decorrido entre a primeira transação do dataset e a atual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols = 1, figsize=(12,7))\n",
    "\n",
    "\n",
    "ax[0].hist(df.Time[df.Class == 1], bins = 30, color= azul, rwidth= 0.9)\n",
    "ax[0].set_title('Transações Fraudulentas',fontsize = 20, \n",
    "                color = preto_titulo, \n",
    "                loc = 'left', \n",
    "                pad= 60, \n",
    "                fontweight= 'bold')\n",
    "ax[0].set_xlabel('Tempo Decorrido (s)', fontsize = 12, color= preto_elementos)\n",
    "ax[0].set_ylabel('Nº de Ocorrências'  , fontsize = 12, color= preto_elementos)\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "ax[1].hist(df.Time[df.Class == 0], bins = 30, color= azul, rwidth= 0.9)\n",
    "ax[1].set_title('Transações Normais',\n",
    "                fontsize = 20,\n",
    "                color = preto_titulo, \n",
    "                loc = 'left', \n",
    "                pad= 60, \n",
    "                fontweight= 'bold')\n",
    "ax[1].set_xlabel('Tempo Decorrido (s)', fontsize = 12, color= preto_elementos)\n",
    "ax[1].set_ylabel('Nº de Ocorrências'  , fontsize = 12, color= preto_elementos)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotando os histogramas da variável \"Amount\" (Fraude e não-fraude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols = 1, figsize=(12,10))\n",
    "\n",
    "\n",
    "ax[0].hist(df.Amount[df.Class == 1], bins = 30, color= azul, rwidth= 0.9)\n",
    "\n",
    "ax[0].text(1900,300, \"Média ${:.2f}\".format(df.Amount[df.Class == 1].mean()),\n",
    "           fontsize = 12, color= preto_elementos)\n",
    "\n",
    "ax[0].set_title('Transações Fraudulentas',\n",
    "                fontsize = 20,\n",
    "                color = preto_titulo, \n",
    "                loc = 'left', \n",
    "                pad= 60, \n",
    "                fontweight= 'bold')\n",
    "ax[0].set_xlabel('Quantidade ($)'   , fontsize = 12, color= preto_elementos)\n",
    "ax[0].set_ylabel('Nº de Ocorrências', fontsize = 12, color= preto_elementos)\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "ax[1].hist(df.Amount[df.Class == 0], bins = 30, color= azul, rwidth= 0.9)\n",
    "\n",
    "ax[1].text(23000,250000, \"Média ${:.2f}\".format(df.Amount[df.Class == 0].mean()),\n",
    "           fontsize = 12, color= preto_elementos)\n",
    "\n",
    "ax[1].set_title('Transações Normais',\n",
    "                fontsize = 20,\n",
    "                color = preto_titulo, \n",
    "                loc = 'left', \n",
    "                pad= 60, \n",
    "                fontweight= 'bold')\n",
    "\n",
    "ax[1].set_xlabel('Quantidade ($)'   , fontsize = 12, color= preto_elementos)\n",
    "ax[1].set_ylabel('Nº de Ocorrências', fontsize = 12, color= preto_elementos)\n",
    "\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout(pad = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As transações fraudulentas tem menos ocorrências neste conjunto de dados, como vimos anteriormente. Talvez por isto a média das transações fraudulentas se mostre maior do que as transações normais, como foi visto no gráfico acima. \n",
    "\n",
    "\n",
    "Vejo que a maioria das transações normais feitas durante esta coleta de dados estão focadas entre 0 e 5000 dólares, com uma média de 88 dólares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot das transações \"fraude\" e \"normais\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,10))\n",
    "\n",
    "sns.boxplot(df.Class, df.Amount, ax=ax, color= azul)\n",
    "plt.ylim((-20, 1500))\n",
    "plt.xticks([0, 1], ['Normal', 'Fraude'],fontsize = 12, color= preto_elementos)\n",
    "\n",
    "ax.set_title('Boxplot - Transações',\n",
    "                fontsize = 20,\n",
    "                color = preto_titulo, \n",
    "                loc = 'left', \n",
    "                pad= 60, \n",
    "                fontweight= 'bold')\n",
    "ax.set_ylabel('Quantidade ($)',fontsize = 12, color= preto_elementos)\n",
    "ax.set_xlabel('')\n",
    "\n",
    "plt.tight_layout(pad = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fiz um corte limitando a quantidade até 1500 dólares com o objetivo de uma visualização mais agradável***\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz de correlação\n",
    "\n",
    "corr_  = df.corr(method= 'spearman')\n",
    "\n",
    "pd.DataFrame(corr_).style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusões da análise exploratória\n",
    "\n",
    "\n",
    "* O dataset não possui valores ausentes para serem tratados.\n",
    "* As classes que representam transações fraudulentas e não-fraudulentas estão totalmente desbalanceadas e isso precisará ser tratado. Se usarmos o conjunto de dados assim mesmo, o modelo não irá generalizar bem o padrão da classe que representa fraude, ficando muito bom apenas em detectar transações não fraudulentas.\n",
    "* As variáveis \"Time\" e \"Amount\" estão em grandezas diferentes do restante das outras *features*. Estas duas colunas precisarão ser normalizadas, já que todo o *dataset* se encontra também normalizado. Caso isso não ocorra, acarretará em dificuldades na hora de treinar o modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULe7z0jZt0EH"
   },
   "source": [
    "# Preparação dos Dados\n",
    "---\n",
    "\n",
    "Aqui, os dados serão preparados para posteriormente haver a criação do modelo e treiná-lo. Nesta etapa irei:\n",
    "\n",
    "* Normalizar os dados que ainda não haviam sido pré-processados (`Time` e `Amount`)\n",
    "* Dividir o conjunto de dados entre treino e teste\n",
    "* Balancear o conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqfjG_SUSTi-"
   },
   "outputs": [],
   "source": [
    "#Criando uma cópia do dataframe\n",
    "\n",
    "df_limpo = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando o algoritmo que usarei para normalizar os dados\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atribuindo ao modelo as variáveis \"Time\" e \"Amount\" e criando novas variáveis dentro do dataframe\n",
    "\n",
    "df_limpo['ss_time'] = scaler.fit_transform(df_limpo[['Time']])\n",
    "df_limpo['ss_amount'] = scaler.fit_transform(df_limpo[['Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deletando as variáveis não-normalizadas\n",
    "\n",
    "df_limpo.drop(['Time', 'Amount'], axis= 1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conferindo o resultado\n",
    "\n",
    "df_limpo.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando as variáveis depedentes e independente\n",
    "\n",
    "X = df_limpo.drop('Class', axis = 1)\n",
    "y = df_limpo['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o conjunto de dados está totalmente desbalanceado onde as transações que não são fraude representam a maior parte das ocorrências, é preciso aplicar técnicas de balanceamento antes de treinar nosso modelo\n",
    "\n",
    "A técnica que eu escolhi é chamada de \"Undersampling\". O método NearMiss da biblioteca [imblearn](https://imbalanced-learn.org/stable/install.html#) é um algoritmo de \"Undersampling\" onde ele basicamente pega a quantidade de ocorrencias que não são fraude e reduz a mesma quantidade das transações que são fraude. Isto é, o algoritmo faz um corte nos dados de modo que a classe com maior ocorrência se reduz e fica igual a classe que tem menos ocorrências. Se treinarmos o nosso modelo simplesmente com dados desbaçanceados, ele vai ficar muito melhor em acertar transações que não são fraude do que as que são. Por isso, balancear os dados nesse cenário é altamente necessário!\n",
    "\n",
    "Além do Undersampling, testei com Oversampling e também aplicando ambas as técnicas. Porém, obtive os melhores resultados usando o Undersampling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando o modelo de Undersampling\n",
    "\n",
    "nm = NearMiss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajustando o modelo com os dados e os atribuindo a novas variáveis\n",
    "\n",
    "X_under, y_under = nm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotando um antes e depois dos dados\n",
    "\n",
    "fig, ax = plt.subplots(ncols= 2, figsize = (15,5))\n",
    "\n",
    "\n",
    "sns.countplot(df.Class, ax = ax[0], color= azul)\n",
    "ax[0].set_title('Antes do Undersampling',\n",
    "                fontsize = 15,\n",
    "                color = preto_titulo, \n",
    "                pad= 10, \n",
    "                fontweight= 'bold')\n",
    "ax[0].set_xlabel('Transação',fontsize = 12, color= preto_elementos)\n",
    "ax[0].set_ylabel('Quantidade de ocorrências',fontsize = 12, color= preto_elementos)\n",
    "ax[0].set_xticklabels(labels = ['Normal','Fraude'],fontsize = 12, color= preto_elementos)\n",
    "\n",
    "\n",
    "sns.countplot(y_under, ax = ax[1], color= azul)\n",
    "ax[1].set_title('Depois do Undersampling',\n",
    "                fontsize = 15,\n",
    "                color = preto_titulo, \n",
    "                pad= 10, \n",
    "                fontweight= 'bold')\n",
    "ax[1].set_xlabel('Transação',fontsize = 12, color= preto_elementos)\n",
    "ax[1].set_ylabel('Quantidade de ocorrências',fontsize = 12, color= preto_elementos)\n",
    "ax[1].set_xticklabels(labels = ['Normal','Fraude'],fontsize = 12, color= preto_elementos)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJNH5qcjRxfX"
   },
   "source": [
    "# Modelo de Machine Learning\n",
    "---\n",
    "Com os dados prontos, é hora de construir nossos modelos. Optei por construir dois modelos afim de compará-los posteriormente. Escolhi usar uma regressão logística e uma árvore de decisão e ver como ambos se saem neste cenário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando os dados entre treino e teste\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDySx8XUSMw_"
   },
   "outputs": [],
   "source": [
    "#Criando um modelo de Regressão Logística e ajustando-o\n",
    "\n",
    "modelo = LogisticRegression()\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previsão dos resultados do modelo de Regressão Logística\n",
    "\n",
    "y_pred = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um novo modelo de árvore de decisão\n",
    "\n",
    "arvore = DecisionTreeClassifier(min_samples_leaf= 2, random_state= 10)\n",
    "arvore.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previsão dos resultados usando árvore de decisão e avaliando-a usando o erro médio quadrado\n",
    "\n",
    "y_pred_arvore = arvore.predict(X_test)\n",
    "\n",
    "print(\"Erro médio quadrado: {}\\n\".format(np.sqrt(mean_squared_error(y_test, y_pred_arvore))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Nos hiperparâmetros da árvore de decisão, afim de evitar um possível overfit existem dois parâmetros que ajudam: `max_depth` e o `min_samples_leaf`. O primeiro, limita a profundidade da nossa árvore, ou seja, quantas camadas ela terá. Já o segundo, ao invés de focar na profundidade, nele é limitado quantas folhas terão em cada camada.\n",
    "\n",
    "Se não colocarmos hiperparâmetro nenhum, a árvore irá treinar o modelo até a profundidade que achar melhor e geralmente até ter uma folha em cada camada. Isso acaba se tornando muito sensível em casos de outliers e também a probabilidade de haver um overfit se torna maior.\n",
    "\n",
    "O padrão que escolhi usar foi o `min_samples_leaf`, acabei tendo um resultado um pouco melhor do que o `max_depth`.Usei como métrica o erro médio quadrado, quanto menor o número, melhor. Aqui vão alguns resultados de testes que fiz:\n",
    "\n",
    "\n",
    "\n",
    "`max_depth`\n",
    "* => none: 0.24680702093691814\n",
    "* => 20: 0.2759386380695814\n",
    "* => 17: 0.2665820508731144\n",
    "* => 18: 0.23629973222959152 - Profundidade Ideal\n",
    "* => 16: 0.30227563311592703\n",
    "\n",
    "\n",
    "`min_samples_leaf`\n",
    "* => 1: 0.23629973222959152\n",
    "* => 2: 0.18850197591499637 - Quantidade de folhas ideal\n",
    "* => 3: 0.23629973222959152\n",
    "\n",
    "\n",
    "Logo abaixo, um plot de como ficou a nossa árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,20))\n",
    "ax = plot_tree(arvore, feature_names= X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e4ENOTYSUXi"
   },
   "source": [
    "## Avaliando o desempenho do modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métricas do modelo - regressão logística\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métricas - árvore de decisão\n",
    "print(classification_report(y_test, y_pred_arvore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotando matriz de confusão - RL\n",
    "\n",
    "print('\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "matriz = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(matriz, square=True, annot=True, cbar=False, cmap= 'Blues')\n",
    "\n",
    "plt.title('Matriz de confusão - Regressão Logística',\n",
    "          fontsize = 12,\n",
    "          color = preto_titulo, \n",
    "          pad= 20, \n",
    "          fontweight= 'bold')\n",
    "\n",
    "plt.xlabel('Previsão do modelo',fontsize = 12, color= preto_elementos)\n",
    "plt.ylabel('Valor verdadeiro'  ,fontsize = 12, color= preto_elementos)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotando matriz de confusão - DT\n",
    "\n",
    "print('\\n', classification_report(y_test, y_pred_arvore))\n",
    "print(\"Erro médio quadrado: {}\\n\".format(np.sqrt(mean_squared_error(y_test, y_pred_arvore))))\n",
    "matriz = confusion_matrix(y_test, y_pred_arvore)\n",
    "sns.heatmap(matriz, square=True, annot=True, cbar=False, cmap= 'Blues')\n",
    "\n",
    "plt.title('Matriz de confusão - Decision Tree',\n",
    "          fontsize = 12,\n",
    "          color = preto_titulo, \n",
    "          pad= 20, \n",
    "          fontweight= 'bold')\n",
    "plt.xlabel('Previsão do modelo',fontsize = 12, color= preto_elementos)\n",
    "plt.ylabel('Valor verdadeiro'  ,fontsize = 12, color= preto_elementos)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Bj7zRZMSfO7"
   },
   "source": [
    "## Conclusão\n",
    "---\n",
    "\n",
    "Os dois modelos escolhidos tiveram resultados bem parecidos, porém a *DesicionTree* se saiu um pouco melhor ao observarmos as métricas do `classification_report`. \n",
    "\n",
    "\n",
    "A diferença entre a *LogisticRegression* e a *DecisionTree* em termos de resultados é que a árvore errou uma previsão da classe \"fraude\" a menos que a regressão logística. \n",
    "\n",
    "\n",
    "Um outro fator a ser considerado é a quantidade de falsos positivos, ou seja, aquelas vezes em que você tentou fazer uma compra e teve seu cartão bloqueado preventivamente. Neste cenário, seria mais interessante focar em acertar mais as transações fraudulentas do que as não-fraudulentas, em outras palavras, melhor um falso positivo em uma transação normal ser fraude do que uma transação fraudulenta ser considerada como normal.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "[Template] Detecção de Fraude em Cartões de Crédito.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
